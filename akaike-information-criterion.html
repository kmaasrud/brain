<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <script src="https://www.kmaasrud.com/web-components/head.js"></script>
    <script src="https://www.kmaasrud.com/web-components/darkModeToggle.js"></script>
    <script src="https://www.kmaasrud.com/web-components/katex.js"></script>
    <script src="https://www.kmaasrud.com/web-components/highlight.js"></script>
    <title>brain/Akaike information criterion</title>
</head>
<body>
    <div id="main">
        <div id="header">brain/<strong>Akaike information criterion</strong></div>
        <script src="https://www.kmaasrud.com/web-components/header.js"></script>
        <div id="content"><div id="content"><p>The <strong>Akaike information criterion</strong> (AIC) is an <a href="estimator">estimator</a> of out-of-sample prediction error, and thus a measure of quality of statistical models, for a given set of data. Its defenition is</p>

<p>$$ \text{AIC} = 2d - 2\text{loglik} ,$$</p>

<p>where $d$ is the number of parameters estimated by the model and $\text{loglik}$ is the log of the maximized <a href="likelihood-function">likelihood function</a>.</p>

<p>Sources:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">Wikipedia</a></li>
<li><a href="the-elements-of-statistical-learning">The Elements of Statistical Learning</a></li>
</ul>
</div><div class="backlinks">

<ul>
<li><a href="stk-in4300-lecture-02-linear-methods-for-regression">STK-IN4300 Lecture 02 - Linear methods for regression</a></li>
</ul>

</div>
</div>
    </div>
</body>
</html>
